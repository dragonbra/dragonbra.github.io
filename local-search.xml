<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>《动手学深度学习》学习笔记 Ch.1 - 前言</title>
    <link href="/2022/02/20/2022/2022-02-20-D2L-Ch1/"/>
    <url>/2022/02/20/2022/2022-02-20-D2L-Ch1/</url>
    
    <content type="html"><![CDATA[<h1 id="1-前言"><a href="#1-前言" class="headerlink" title="1. 前言"></a>1. 前言</h1><h2 id="1-1-日常生活中的机器学习"><a href="#1-1-日常生活中的机器学习" class="headerlink" title="1.1. 日常生活中的机器学习"></a>1.1. 日常生活中的机器学习</h2><p>如图所示，训练过程通常包含如下步骤：</p><ol><li>从一个随机初始化参数的模型开始，这个模型基本毫不“智能”。</li><li>获取一些数据样本（例如，音频片段以及对应的{是,否}{是,否}标签）。</li><li>调整参数，使模型在这些样本中表现得更好。</li><li>重复第2步和第3步，直到模型在任务中的表现令你满意。</li></ol><p><img src="https://zh.d2l.ai/_images/ml-loop.svg" alt="机器学习"></p><h2 id="1-2-关键组件"><a href="#1-2-关键组件" class="headerlink" title="1.2. 关键组件"></a>1.2. 关键组件</h2><ol><li>我们可以学习的<em>数据</em>（data）。</li><li>如何转换数据的<em>模型</em>（model）。</li><li>一个<em>目标函数</em>（objective function），用来量化模型的有效性。</li><li>调整模型参数以优化目标函数的<em>算法</em>（algorithm）。</li></ol><h3 id="1-2-1-数据"><a href="#1-2-1-数据" class="headerlink" title="1.2.1. 数据"></a>1.2.1. 数据</h3><p>毋庸置疑，如果没有数据，那么数据科学毫无用武之地。 每个数据集由一个个<em>样本</em>（example, sample）组成，大多时候，它们遵循独立同分布(independently and identically distributed, i.i.d.)。 样本有时也叫做<em>数据点</em>（data point）或者<em>数据实例</em>（data instance），通常每个样本由一组称为<em>特征</em>（features，或<em>协变量</em>（covariates））的属性组成。 机器学习模型会根据这些属性进行预测。 在上面的监督学习问题中，要预测的是一个特殊的属性，它被称为<em>标签</em>（label，或<em>目标</em>（target））。</p><p>如果数据中充满了错误，或者如果数据的特征不能预测任务目标，那么模型很可能无效。 有一句古语很好地反映了这个现象：“输入的是垃圾，输出的也是垃圾。”（“Garbage in, garbage out.”）</p><h3 id="1-2-2-模型"><a href="#1-2-2-模型" class="headerlink" title="1.2.2. 模型"></a>1.2.2. 模型</h3><p>深度学习与经典方法的区别主要在于：前者关注的功能强大的模型，这些模型由神经网络错综复杂的交织在一起，包含层层数据转换，因此被称为<em>深度学习</em>（deep learning）。</p><h3 id="1-2-3-目标函数"><a href="#1-2-3-目标函数" class="headerlink" title="1.2.3. 目标函数"></a>1.2.3. 目标函数</h3><p> 在机器学习中，我们需要定义模型的优劣程度的度量，这个度量在大多数情况是“可优化”的，我们称之为<em>目标函数</em>（objective function）。 我们通常定义一个目标函数，并希望优化它到最低点。 因为越低越好，所以这些函数有时被称为<em>损失函数</em>（loss function，或cost function）。</p><p>当任务在试图预测数值时，最常见的损失函数是<em>平方误差</em>（squared error），即预测值与实际值之差的平方。 </p><p>通常，损失函数是根据模型参数定义的，并取决于数据集。 在一个数据集上，我们通过最小化总损失来学习模型参数的最佳值。 该数据集由一些为训练而收集的样本组成，称为<em>训练数据集</em>（training dataset，或称为<em>训练集</em>（training set））。 然而，在训练数据上表现良好的模型，并不一定在“新数据集”上有同样的效能，这里的“新数据集”通常称为<em>测试数据集</em>（test dataset，或称为<em>测试集</em>（test set））。</p><h3 id="1-2-4-优化算法"><a href="#1-2-4-优化算法" class="headerlink" title="1.2.4. 优化算法"></a>1.2.4. 优化算法</h3><p>深度学习中，大多流行的优化算法通常基于一种基本方法–<em>梯度下降</em>（gradient descent）。 简而言之，在每个步骤中，梯度下降法都会检查每个参数，看看如果你仅对该参数进行少量变动，训练集损失会朝哪个方向移动。 然后，它在可以减少损失的方向上优化参数。</p><h2 id="1-3-各种机器学习问题"><a href="#1-3-各种机器学习问题" class="headerlink" title="1.3. 各种机器学习问题"></a>1.3. 各种机器学习问题</h2><h3 id="1-3-1-监督学习"><a href="#1-3-1-监督学习" class="headerlink" title="1.3.1. 监督学习"></a>1.3.1. 监督学习</h3><p><em>监督学习</em>（supervised learning）擅长在“给定输入特征”的情况下预测标签。 每个“特征-标签”对都称为一个<em>样本</em>（example）。 </p><p>虽然监督学习只是几大类机器学习问题之一，但是在工业中，大部分机器学习的成功应用都是监督学习。 这是因为在一定程度上，许多重要的任务可以清晰地描述为：在给定一组特定的可用数据的情况下，估计未知事物的概率。比如：</p><ul><li>根据计算机断层扫描（CT）肿瘤图像，预测是否为癌症。</li><li>给出一个英语句子，预测正确的法语翻译。</li><li>根据本月的财务报告数据，预测下个月股票的价格。</li></ul><p><img src="https://zh.d2l.ai/_images/supervised-learning.svg" alt="监督学习"></p><h4 id="1-3-1-1-回归"><a href="#1-3-1-1-回归" class="headerlink" title="1.3.1.1. 回归"></a>1.3.1.1. 回归</h4><p><em>回归</em>（regression）是最简单的监督学习任务之一。假设你在市场上寻找新房子，你可能需要估计一栋房子的公平市场价值。 销售价格，即标签，是一个数值。 当标签取任意数值时，我们称之为<em>回归</em>问题。</p><p>总而言之，判断回归问题的一个很好的经验法则是，任何有关“多少”的问题很可能就是回归问题。比如：</p><ul><li>这个手术需要多少小时？</li><li>在未来六小时，这个镇会有多少降雨量？</li></ul><h4 id="1-3-1-2-分类"><a href="#1-3-1-2-分类" class="headerlink" title="1.3.1.2. 分类"></a>1.3.1.2. 分类</h4><p>在<em>分类</em>问题中，我们希望模型能够预测样本属于哪个<em>类别</em>（category，正式称为<em>类</em>（class））。 </p><p>当我们有两个以上的类别时，我们把这个问题称为<em>多元分类</em>（multiclass classification）问题。 常见的例子包括手写字符识别 {0,1,2,…9,a,b,c,…}。 与解决回归问题不同，分类问题的常见损失函数被称为<em>交叉熵</em>（cross-entropy），我们将在后面的章节中详细阐述。</p><h4 id="1-3-1-3-标记问题"><a href="#1-3-1-3-标记问题" class="headerlink" title="1.3.1.3. 标记问题"></a>1.3.1.3. 标记问题</h4><p>学习预测不相互排斥的类别的问题称为<em>多标签分类</em>（multi-label classification）。</p><h4 id="1-3-1-4-搜索"><a href="#1-3-1-4-搜索" class="headerlink" title="1.3.1.4. 搜索"></a>1.3.1.4. 搜索</h4><p>有时，我们不仅仅希望输出为一个类别或一个实值。 在信息检索领域，我们希望对一组项目进行排序。以网络搜索为例，我们的目标不是简单的“查询（query）-网页（page）”分类，而是在海量搜索结果中找到用户最需要的那部分。</p><h4 id="1-3-1-5-推荐系统"><a href="#1-3-1-5-推荐系统" class="headerlink" title="1.3.1.5. 推荐系统"></a>1.3.1.5. 推荐系统</h4><p>另一类与搜索和排名相关的问题是<em>推荐系统</em>（recommender system），它的目标是向特定用户进行“个性化”推荐。 例如，对于电影推荐，科幻迷和喜剧爱好者的推荐结果页面可能会有很大不同。 类似的应用也会出现在零售产品、音乐和新闻推荐等等。</p><h4 id="1-3-1-6-序列学习"><a href="#1-3-1-6-序列学习" class="headerlink" title="1.3.1.6. 序列学习"></a>1.3.1.6. 序列学习</h4><ol><li><strong>标记和解析</strong>。这涉及到用属性注释文本序列。 </li><li><strong>自动语音识别</strong>。</li><li><strong>文本到语音</strong>。这与自动语音识别相反。 </li><li><strong>机器翻译</strong>。 在语音识别中，输入和输出的出现顺序基本相同。 而在机器翻译中，颠倒输入和输出的顺序非常重要。</li></ol><h3 id="1-3-2-无监督学习"><a href="#1-3-2-无监督学习" class="headerlink" title="1.3.2. 无监督学习"></a>1.3.2. 无监督学习</h3><p>如果你的工作没有十分具体的目标，你就需要“自发”地去学习了。 （如果你打算成为一名数据科学家，你最好培养这个习惯。） 比如，你的老板可能会给你一大堆数据，然后让你用它做一些数据科学研究，却没有对结果有要求。 我们称这类数据中不含有“目标”的机器学习问题为<em>无监督学习</em>（unsupervised learning）， 我们将在后面的章节中讨论无监督学习技术。 那么无监督学习可以回答什么样的问题呢？我们来看看下面的例子：</p><ul><li><em>聚类</em>（clustering）问题：没有标签的情况下，我们是否能给数据分类呢？比如，给定一组照片，我们能把它们分成风景照片、狗、婴儿、猫和山峰的照片吗？同样，给定一组用户的网页浏览记录，我们能否将具有相似行为的用户聚类呢？</li><li><em>主成分分析</em>（principal component analysis）问题：我们能否找到少量的参数来准确地捕捉数据的线性相关属性？比如，一个球的运动轨迹可以用球的速度、直径和质量来描述。</li><li><em>因果关系</em>（causality）和<em>概率图模型</em>（probabilistic graphical models）问题：我们能否描述观察到的许多数据的根本原因？例如，如果我们有关于房价、污染、犯罪、地理位置、教育和工资的人口统计数据，我们能否简单地根据经验数据发现它们之间的关系？</li><li><em>生成对抗性网络</em>（generative adversarial networks）：为我们提供一种合成数据的方法，甚至像图像和音频这样复杂的非结构化数据。潜在的统计机制是检查真实和虚假数据是否相同的测试，它是无监督学习的另一个重要而令人兴奋的领域。</li></ul><h3 id="1-3-3-与环境互动"><a href="#1-3-3-与环境互动" class="headerlink" title="1.3.3. 与环境互动"></a>1.3.3. 与环境互动</h3><p>到目前为止，不管是监督学习还是无监督学习，我们都会预先获取大量数据，然后启动模型，不再与环境交互。 这里所有学习都是在算法与环境断开后进行的，被称为<em>离线学习</em>（offline learning）。</p><p><img src="https://zh.d2l.ai/_images/data-collection.svg" alt="从环境中为监督学习收集数据。"></p><p>考虑“与真实环境互动”将打开一整套新的建模问题。以下只是几个例子：</p><ul><li>环境还记得我们以前做过什么吗？</li><li>环境是否有助于我们建模？例如，用户将文本读入语音识别器。</li><li>环境是否想要打败模型？例如，一个对抗性的设置，如垃圾邮件过滤或玩游戏？</li><li>环境是否重要？</li><li>环境是否变化？例如，未来的数据是否总是与过去相似，还是随着时间的推移会发生变化？是自然变化还是响应我们的自动化工具而发生变化？</li></ul><p>当训练和测试数据不同时，最后一个问题提出了<em>分布偏移</em>（distribution shift）的问题。 接下来，我们将简要描述强化学习问题，这是一类明确考虑与环境交互的问题。</p><h3 id="1-3-4-强化学习"><a href="#1-3-4-强化学习" class="headerlink" title="1.3.4. 强化学习"></a>1.3.4. 强化学习</h3><p>如果你对使用机器学习开发与环境交互并采取行动感兴趣，那么你最终可能会专注于<em>强化学习</em>（reinforcement learning）。 这可能包括应用到机器人、对话系统，甚至开发视频游戏的人工智能（AI）。 <em>深度强化学习</em>（deep reinforcement learning）将深度学习应用于强化学习的问题，是非常热门的研究领域。 突破性的深度<em>Q网络</em>（Q-network）在雅达利游戏中仅使用视觉输入就击败了人类， 以及 AlphaGo 程序在棋盘游戏围棋中击败了世界冠军，是两个突出强化学习的例子。</p><p>在强化学习问题中，agent在一系列的时间步骤上与环境交互。 在每个特定时间点，agent从环境接收一些<em>观察</em>（observation），并且必须选择一个<em>动作</em>（action），然后通过某种机制（有时称为执行器）将其传输回环境，最后agent从环境中获得<em>奖励</em>（reward）。 此后新一轮循环开始，agent接收后续观察，并选择后续操作，依此类推。 强化学习的过程在 <a href="https://zh.d2l.ai/chapter_introduction/index.html#fig-rl-environment">图1.3.7</a> 中进行了说明。 请注意，强化学习的目标是产生一个好的<em>策略</em>（policy）。 强化学习agent选择的“动作”受策略控制，即一个从环境观察映射到行动的功能。</p><p><img src="https://zh.d2l.ai/_images/rl-environment.svg" alt="强化学习和环境之间的相互作用"></p><p>当环境可被完全观察到时，我们将强化学习问题称为<em>马尔可夫决策过程</em>（markov decision process）。 当状态不依赖于之前的操作时，我们称该问题为<em>上下文赌博机</em>（contextual bandit problem）。 当没有状态，只有一组最初未知回报的可用动作时，这个问题就是经典的<em>多臂赌博机</em>（multi-armed bandit problem）。</p><h2 id="1-4-起源"><a href="#1-4-起源" class="headerlink" title="1.4. 起源"></a>1.4. 起源</h2><p><em>神经网络</em>（neural networks）的得名源于生物灵感。 一个多世纪以来（追溯到1873年亚历山大·贝恩和1890年詹姆斯·谢林顿的模型），研究人员一直试图组装类似于相互作用的神经元网络的计算电路。 随着时间的推移，对生物学的解释变得不再肤浅，但这个名字仍然存在。 其核心是当今大多数网络中都可以找到的几个关键原则：</p><ul><li>线性和非线性处理单元的交替，通常称为<em>层</em>（layers）。</li><li>使用链式规则（也称为<em>反向传播</em>（backpropagation））一次性调整网络中的全部参数。</li></ul><p>在最初的快速发展之后，神经网络的研究从1995年左右一直开始停滞不前，直到到2005年才稍有起色。 这主要是因为两个原因。 首先，训练网络（在计算上）非常昂贵。 在上个世纪末，随机存取存储器（RAM）非常强大，而计算能力却很弱。 其次，数据集相对较小。 事实上，费舍尔1932年的鸢尾花卉数据集是测试算法有效性的流行工具， 而MNIST数据集的60000个手写数字的数据集被认为是巨大的。 考虑到数据和计算的稀缺性，<em>核方法</em>（kernel method）、<em>决策树</em>（decision tree）和<em>图模型</em>（graph models）等强大的统计工具（在经验上）证明是更为优越的。 与神经网络不同的是，这些算法不需要数周的训练，而且有很强的理论依据，可以提供可预测的结果。</p><h2 id="1-5-深度学习之路"><a href="#1-5-深度学习之路" class="headerlink" title="1.5. 深度学习之路"></a>1.5. 深度学习之路</h2><p>大约2010年开始，那些在计算上看起来不可行的神经网络算法变得热门起来，实际上是以下两点导致的： 其一，随着互联网的公司的出现，为数亿在线用户提供服务，大规模数据集变得触手可及。 另外，廉价又高质量的传感器、廉价的数据存储（克莱德定律）以及廉价计算（摩尔定律）的普及，特别是GPU的普及，使大规模算力唾手可得。</p><h2 id="1-6-成功案例"><a href="#1-6-成功案例" class="headerlink" title="1.6. 成功案例"></a>1.6. 成功案例</h2><p>直到最近，人工智能才成为人们关注的焦点，主要是因为解决了以前被认为难以解决的问题，这些问题与消费者直接相关。许多这样的进步都归功于深度学习。</p><ul><li>智能助理，如苹果的Siri、亚马逊的Alexa和谷歌助手，都能够相当准确地回答口头问题。这包括一些琐碎的工作，比如打开电灯开关（对残疾人来说是个福音）甚至预约理发师和提供电话支持对话。这可能是人工智能正在影响我们生活的最明显的迹象。</li><li>数字助理的一个关键要素是准确识别语音的能力。逐渐地，在某些应用中，此类系统的准确性已经提高到与人类同等水平的程度 [<a href="https://zh.d2l.ai/chapter_references/zreferences.html#xiong-wu-alleva-ea-2018">Xiong et al., 2018]</a>。</li><li>物体识别同样也取得了长足的进步。估计图片中的物体在2010年是一项相当具有挑战性的任务。在ImageNet基准上，来自NEC实验室和伊利诺伊大学香槟分校的研究人员获得了28%的Top-5错误率 [<a href="https://zh.d2l.ai/chapter_references/zreferences.html#lin-lv-zhu-ea-2010">Lin et al., 2010]</a> 。到2017年，这一错误率降低到2.25% [<a href="https://zh.d2l.ai/chapter_references/zreferences.html#hu-shen-sun-2018">Hu et al., 2018]</a> 。同样，在鉴别鸟类或诊断皮肤癌方面也取得了惊人的成果。</li><li>游戏曾经是人类智慧的堡垒。从TD-Gammon开始，一个使用时差强化学习的五子棋游戏程序，算法和计算的进步导致了算法被广泛应用。与五子棋不同的是，国际象棋有一个复杂得多的状态空间和一组动作。深蓝公司利用大规模并行性、专用硬件和高效搜索游戏树 [<a href="https://zh.d2l.ai/chapter_references/zreferences.html#campbell-hoane-jr-hsu-2002">Campbell et al., 2002]</a> 击败了加里·卡斯帕罗夫(Garry Kasparov)。围棋由于其巨大的状态空间，难度更大。AlphaGo在2015年达到了相当于人类的棋力，使用和蒙特卡洛树抽样 [<a href="https://zh.d2l.ai/chapter_references/zreferences.html#silver-huang-maddison-ea-2016">Silver et al., 2016]</a> 相结合的深度学习。扑克中的挑战是状态空间很大，而且没有完全观察到（我们不知道对手的牌）。在扑克游戏中，库图斯使用有效的结构化策略超过了人类的表现 [<a href="https://zh.d2l.ai/chapter_references/zreferences.html#brown-sandholm-2017">Brown &amp; Sandholm, 2017]</a> 。这说明了游戏取得了令人瞩目的进步以及先进的算法在其中发挥了关键作用的事实。</li><li>人工智能进步的另一个迹象是自动驾驶汽车和卡车的出现。虽然完全自主还没有完全触手可及，但在这个方向上已经取得了很好的进展，特斯拉（Tesla）、英伟达（NVIDIA）和Waymo等公司的产品至少实现了部分自主。让完全自主如此具有挑战性的是，正确的驾驶需要感知、推理和将规则纳入系统的能力。目前，深度学习主要应用于这些问题的计算机视觉方面。其余部分则由工程师进行大量调整。</li></ul><h2 id="1-7-特点"><a href="#1-7-特点" class="headerlink" title="1.7. 特点"></a>1.7. 特点</h2><p>到目前为止，我们已经广泛地讨论了机器学习，它既是人工智能的一个分支，也是人工智能的一种方法。 虽然深度学习是机器学习的一个子集，但令人眼花缭乱的算法和应用程序集让人很难评估深度学习的具体成分是什么。 这就像试图确定披萨所需的配料一样困难，因为几乎每种成分都是可以替代的。</p><h2 id="1-8-小结"><a href="#1-8-小结" class="headerlink" title="1.8. 小结"></a>1.8. 小结</h2><ul><li>机器学习研究计算机系统如何利用经验（通常是数据）来提高特定任务的性能。它结合了统计学、数据挖掘和优化的思想。通常，它是被用作实现人工智能解决方案的一种手段。</li><li>表示学习作为机器学习的一类，其研究的重点是如何自动找到合适的数据表示方式。深度学习是通过学习多层次的转换来进行的多层次的表示学习。</li><li>深度学习不仅取代了传统机器学习的浅层模型，而且取代了劳动密集型的特征工程。</li><li>最近在深度学习方面取得的许多进展，大都是由廉价传感器和互联网规模应用所产生的大量数据，以及（通过GPU）算力的突破来触发的。</li><li>整个系统优化是获得高性能的关键环节。有效的深度学习框架的开源使得这一点的设计和实现变得非常容易。</li></ul>]]></content>
    
    
    <categories>
      
      <category>知识与总结</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>学习笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2021厦门大学CS保研经历 | 夏令营游记 | MAC实验室</title>
    <link href="/2021/10/26/2021/2021-10-26-XMU-Summer-Camp/"/>
    <url>/2021/10/26/2021/2021-10-26-XMU-Summer-Camp/</url>
    
    <content type="html"><![CDATA[<h2 id="【个人情况】"><a href="#【个人情况】" class="headerlink" title="【个人情况】"></a>【个人情况】</h2><p>本科：南京某不知名211，计算机科学与技术专业<br>排名：12/242（夏令营绩点排名），5/242（预推免综排）<br>荣誉奖项：2020年国家奖学金<br>竞赛经历：ICPC EC 铜牌，江苏省赛银牌第二，CSP 390分等ACM相关<br>项目经历：软件杯三等奖 * 2<br>科研经历：几乎无<br>实习经历：7月中-9月底在腾讯实习（然而并没在保研过程中写进简历）<br>最终去向：厦门大学CS学硕，MAC实验室</p><h2 id="【院校选择】"><a href="#【院校选择】" class="headerlink" title="【院校选择】"></a>【院校选择】</h2><p>其实在保研正式开始前，对自己的定位还是倾向于就业，我的优势是ACM打的多，<del>劣势是没打出成绩x</del>，CSP也有前1%，劣势是科研项目经历比较少。原本的打算找羊导在研究生期间疯狂刷实习经历最后去大厂，也是因此在大三下学期初面试拿了腾讯实习的offer，但这可能也是这次实习坚定了我最后选择厦大MAC的决心吧，不过是后话了。</p><p>按往年的情况分析，自己大概率能在预推免时候上岸华五软院（特指南软浙软）专硕。本人对学硕和科研没有太大执念，但是也不排斥，如果方向感兴趣也可以考虑尝试。目标院校层次大概是南软or浙软或北航、同济、电科、华师等（个人感觉南软浙软和别的选择有很大的区别，可能是偏向牌子刷简历，但就业去向基本全靠自己这样）。</p><p>投递夏令营的时候还是处于比较迷茫的状态，于是选择了对着GitHub仓库把大部分中九及以上都投递了一遍（当然也是被刷得很惨了TUT）。</p><h2 id="【入营情况】"><a href="#【入营情况】" class="headerlink" title="【入营情况】"></a>【入营情况】</h2><p>简历投递和入营开奖是一场持久战……很多同学到最后甚至因为投递&amp;入营太多，懒得关注其他中九的开营情况了，而入营开奖更是让人煎熬。一边经历着最心累的一次期末备考，一边天天关注着开奖情况。厦大是最早开的，北航由于夏令营的时间和厦大冲突了，而且厦大是线下，所以后来选择撤回报名，打算预推免再报。过了很久之后，收到了同济的入营，之后等了很久，但再也没有了……</p><p>入营后开始了解学校老师的情况，也是入营厦大后才了解到厦大的纪荣嵘老师和MAC实验室，当时就去实验室主页和纪老师的个人主页看了看。并且在了解到纪老师的研究方向以及<strong>最最打动我</strong>的招生介绍后，立刻和纪老师发了邮件，也得到了回复。同济方面，我找在同济CS的高中同学了解了一下情况后，也联系了同济SLAM的老师，但是可能正值期末，老师过了一周后才回复了我欢迎报考的邮件。</p><p>最终入营情况：厦门大学信息学院CS系，同济大学电院CS系。<br>（华师、南软都被刷，心里其实挺不好受的……但这也充分说明了夏令营阶段绩点排名才是yyds）</p><h2 id="【面试经验】"><a href="#【面试经验】" class="headerlink" title="【面试经验】"></a>【面试经验】</h2><ul><li><strong>厦门大学（7.9-7.11）</strong></li></ul><p>厦大是今年比较少有的线下举办的夏令营，7.9下午从南京飞到厦门，去厦门大学海韵校区报到领取宿舍钥匙等生活用品，晚上开营仪式。路上还结识了HEU的金牌爷爷。厦大CS系的考核比较多，第一天上午机试，下午笔试，第二天面试。没记错的话分数比例应该是3:3:4。</p><p><img src="/img/2021-10-26-XMU-Summer-Camp/XMU_welcome.jpeg" alt="厦大报到"></p><p>机考挺简单的，三道题，两小时。毕竟ACM签到这么多年……半小时左右就第一个AK了，坐了一会儿出来了，后续应该陆陆续续有3、40的人都AK了？第一题是矩阵蛇形填充，第二题是最大子段和，第三题是结构体的排序。机试完进行了系内实验室和老师的介绍讲座，1. MAC实验室没来CS系宣讲，不知道AI系那边有没有 2. CS系这边最大的ASC实验室似乎也是做SLAM的，王程教授的气场真的很足……</p><p>笔试破防了，一点点。全考算法与数据结构，九道大题，主要是各种基础算法和数据结构的考察，难度中等，但我确实没考太好。考前还匆忙看了下厦大本科生的教材，重点看了下哈希和排序那块的考法顺便加深了下印象。但是卷子里的B-树插入过程和AOE网的题属实没防住，确实基础不牢还没全面复习，应该是被拉了一定的分……当晚和同校通信专业的同学一起去找厦大学姐，下午带我们逛了逛校园，晚上去思明的海边沙滩踩水。住在海边真的太棒了，很惬意~</p><p><img src="/img/2021-10-26-XMU-Summer-Camp/XMU_campus.jpeg" alt="厦大校园"></p><p><img src="/img/2021-10-26-XMU-Summer-Camp/XMU_MAC.jpeg" alt="厦大MAC"></p><p>第二天分组到上午进行面试，面试过程挺顺利的，首先是英文2分钟自我介绍+ppt中文展示个人情况。老师们主要围绕我的项目提了几个问题，考察了一下项目相关的算法原理是否清楚了解。当时印象很深刻的是王程教授正好在我这组，第一个问题是厦大如果给我offer我会来吗，走前最后一句话是跟我说我拿了优营就一定要来，不管是去哪个实验室。</p><p>当天中午收到了联系的MAC实验室老师的邮件和电话，说她也在我参加面试的那组，对我的表现很满意，如果我想去MAC愿意为我留个位置，可以免考核去。当时真的超级开心！！感觉这三年逐渐给自己增加的压力和焦虑、迷茫都在这一瞬间值得了，自己向往的去向也给予我了这份认可。从那时起就开始非常认真地考虑自己是不是就要去厦大MAC了。</p><ul><li><strong>同济大学（未参加考核，7.12-7.14）</strong></li></ul><p>同济大学是线上举办夏令营，按同学的话说，非常类似一场小考研，专业课+机考+英语+面试……按往年的经验看，最后就是夏令营和预推免的同学按成绩总分的高低排序，顺序录取，所以夏令营可能也没有太大的优势。</p><p>听宣讲的时候就有点三心二意了，一边想着厦大的offer，一边也很忐忑自己这最近的状态可能根本没准备好这场专业课大联考，而且如果拿到同济的offer，地理位置&amp;导师选择还是让我一直都在犹豫要不要继续参加。感谢当时一直听我纠结自己事情的同学、学长，最后也是觉得厦大MAC都要我了，中九好像没什么必要看，同济对我来讲也没有那么大的吸引力了，遂放弃。</p><p>放弃同济那晚，心里一块大石头也算落了地，一个人在深圳的酒店里好好哭了一场。</p><ul><li><strong>预推免（未参加，等厦大学硕候补）</strong></li></ul><p>其实在当时我看来，我已经是决定了要去从零开始我的CV生涯了，而且厦大MAC在我心里的权重，已经完全打败了其他的中九。并且我觉得华五CS就算我努努力拿到了它专硕的offer，可能在导师和研究方向上又没有选择权。而且那时的我在经受了腾讯实习的毒打后，也是越发觉得南软or浙软的学习生活应该不是我想要的那种。并且也在拿到厦大优营后签了承诺书，于是整个八九月也就没有继续准备预推免和参加别的环节了，全程在等待厦大的候补。</p><p>不得不说厦大的学硕名额确实是有点少，夏令营也只有12个……我自己在笔试的表现也不够好，所以只有等。期间也有学长表示不理解我为什么守着厦大专硕不试试别的学校，心态也确实越发焦虑，不过很幸运，927晚上通知我补录到了（厦大的鸽子也是真的很多……）。我的保研也就落下帷幕了~</p><h2 id="【一些感慨】"><a href="#【一些感慨】" class="headerlink" title="【一些感慨】"></a>【一些感慨】</h2><h3 id="1-厦大给我的印象真的太美好了"><a href="#1-厦大给我的印象真的太美好了" class="headerlink" title="1. 厦大给我的印象真的太美好了"></a>1. 厦大给我的印象真的太美好了</h3><p>我的本科学校是一所理工气氛相当浓厚的院校，学校面积小，人文气息不是很重，甚至常常感觉晚上的校园太安静了，甚至可以说有点死气沉沉。自己这三年又一直在各种莫名其妙地卷，感觉自己过得不太开心，这种感觉尤其是到了大三的下学期积蓄到了顶峰。</p><p>但是在厦大夏令营时，第一次在大学里感受到这样温暖和惬意，感觉自己的灵魂得到了净化。与其难受地学习生活、为了未来莫名其妙地卷，不如至少选个自己待着舒服的地方吧。我理解了厦大为什么坚持要线下开夏令营，也成功被她的魅力拐走了。</p><center>    <img src="/img/2021-10-26-XMU-Summer-Camp/chat_1.jpg" width="50%">    <br>    <font size="2" face="cursive" color="#999">聊天记录1</font>    <br><br>    <img src="/img/2021-10-26-XMU-Summer-Camp/chat_2.jpg" width="50%">    <br>    <font size="2" face="cursive" color="#999">聊天记录2</font></center><h3 id="2-建议大家还是不要学我"><a href="#2-建议大家还是不要学我" class="headerlink" title="2. 建议大家还是不要学我"></a>2. 建议大家还是不要学我</h3><p>从学长学姐那的经验&amp;其他帖子的分享说到，厦大是很看重诚信的，自己给的优营一定是不会咕的，但是会有很多学生咕厦大。个人的体验看来也是如此，由于去年我校学长学姐有咕厦大的经历，所以非常明显地体现在了今年入营的情况上，CS和AI专业我校入营人数相比去年少了非常多。从去年前年关注保研到现在，真的看到了太多学校咕学生的案例，自己的内心也是给某些学校画上了重点符号，学校海，学生也海，相互猜疑，感觉这样的推免过程真的很不正常。在这样的情况下受伤更多的总还是老实人学生，希望像厦大这样的学校能更多吧。</p><p>所以一点个人建议：首先就是不要学我做老实人，第二就是不要学我做躺平人……当然这也和每个人具体的情况和选择有关系，总之希望大家抓住机会，提前联系老师，保研过程一切顺利吧！</p>]]></content>
    
    
    <categories>
      
      <category>学习与工作</category>
      
    </categories>
    
    
    <tags>
      
      <tag>日记</tag>
      
      <tag>厦门大学</tag>
      
      <tag>保研夏令营</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>我在腾讯实习的第一周 | Dragonbra的第一篇博客</title>
    <link href="/2021/07/18/2021/2021-07-18-Internship/"/>
    <url>/2021/07/18/2021/2021-07-18-Internship/</url>
    
    <content type="html"><![CDATA[<h1 id="正文前的吐槽"><a href="#正文前的吐槽" class="headerlink" title="正文前的吐槽"></a>正文前的吐槽</h1><p>2021-07-18的晚上，今天已经是入职后的第一个周日了，经历了两天的忙碌租房和回酒店躺尸后，我又回到了我的工位<del>（为了夜宵券）</del>，终于有时间提笔来写这篇博客了。</p><p>其实上周一就火急火燎地赶来深圳了，在鹅厂提供的大house住了几天才在15号去报到，究其原因，还得问问为什么我的期末考试、软件杯DDL、厦大和同济的夏令营能那么满满当当地给我排在一起……</p><h1 id="Day01-报到"><a href="#Day01-报到" class="headerlink" title="Day01 - 报到"></a>Day01 - 报到</h1><blockquote><ul><li>居然就捡到了别人的Token（听导师说遗失罚款500）</li></ul></blockquote><p>其实早在三月初，我就接到了这次来实习的offer，结果七月中才来，心里还想着，我不会是最晚来的了吧。（谁知道这学期课这么多，为了保研……忍了）</p><p>15号当天，来到T站，领取了入职大礼包~（当天排队的人好多，又是大热天，沿着深南大道走那一路都让我浑身汗湿了，排队更是雪上加霜……感受到了夏天的恶意┭┮﹏┭┮）</p><p><img src="/img/2021-07-18-Internship/%E5%B7%A5%E5%8D%A1.png" alt="报到领取的工卡"></p><p>↑ 大家看这张工卡，不知道有没有细心的同学能看出来，我是硬掰开那个铁环塞进了我的工卡套的（原因可能是小姐姐忘记给我那个可拉伸的标着“Tencent”的小零件了，以致于后续……）</p><p>在我收拾收拾准备刷卡离开T站的时候，后面的小姐姐叫住我：“是不是你的Token掉了？”我半信半疑地接了过来（因为上面有我没有的那个”Tencent”的小圆牌啊！），带回了自己的工位。</p><p>结果我后续在新人报到群里问了下，有人帮我查了一下Token的序列号，果然不是我的。（那么旧又脏脏的，我想也不至于……）于是后来在企微上拉了个小群，约了一下见面地点就归还给那位同学了。</p><h1 id="Day01-导师与吃饭"><a href="#Day01-导师与吃饭" class="headerlink" title="Day01 - 导师与吃饭"></a>Day01 - 导师与吃饭</h1><p>报到后，我就自己拿着工卡前往部门所在的位置了。因为前一天也有联系，大概知道在哪里。怀揣着激动的心情，背着被QGG公仔填满的书包，冲上了腾大隔壁的大族。结果到了部门后，陷入了迷茫……没想到一层楼里这么大，人也很多，我不敢乱跑，在茶水间给导师和Leader打电话发微信也没有回我，最后还是可怜巴巴地被之前群里认识的同学领了进去，发现导师和Leader正在一起面谈事情。</p><p><img src="/img/2021-07-18-Internship/%E5%A4%A7%E6%97%8F%E5%A4%A7%E5%8E%A6.jpeg" alt="大族大厦"></p><p>大概自我介绍后，和导师相认。被带到了工位，愉快地”看着“自己即将使用的iMac纸箱（因为没工位了，坐不下，所以暂时没法拆 <del>这就是晚来的坏处吗</del> ）后来一直到11点多，部门秘书才告诉我可以搬去一个临时工位，但是这个位置上好像还是有人的，只是请了一周的假，不知道下周一会怎么办啊。</p><p>拆开Mac，简单组装了一下，意外发现配置居然比之前短信说的翻了个倍（指内存16G→32G，不知道是不是前任主人自己加的），小开心。简单装了下环境，买了一下五折Q币，就被导师领去吃饭了~</p><p>附近以腾大为中心的几栋楼都是腾讯的，不得不感慨一声，有钱真好。</p><p>中午在附近的购物中心里吃的，因为人实在是太多了，和导师还有当时一面面我的面试官一起，简单吃了碗牛肉面。晚上导师带我去腾大吃了吃自选食堂，还演示了一次夜宵券的用法O(∩_∩)O哈哈！感觉接下来两三个月里，有够吃了！</p><h1 id="Day02-工作与任务"><a href="#Day02-工作与任务" class="headerlink" title="Day02 - 工作与任务"></a>Day02 - 工作与任务</h1><p>第一天下午，简单和导师还有Leader一起聊了聊，确认了我最近的工作上的任务：先自己熟悉一下objective-C的语法，学习学习，读读组里的文档和源码，到觉得自己能理解了的时候，差不多也会给我提任务和需求交给我来完成了~</p><p>第二天的下午，正好到了组里周会的时间，开了快两个小时，和在别处办公的小伙伴们一起远程协商沟通，还看到了好多前两周还在软件工程这门课的PPT和卷子上折磨我的知识点，对组里的工作稍微有了更全面的了解吧~</p><p>这两天基本上都在配环境和读文档（dfs读文档读了一整个上午……还没完全看完），感觉新人刚来，想正式上手项目还有不短的一段路要走，尤其是我这种可能没什么实习经验的。同组还有几位实习生，但我好像是里面最小的，大家都是研二研三来实习，我知道的只有我还是本科qwq。感觉组里氛围很好，大家人都很nice的样子。（虽然大家好像对我的id很在意……）而且感觉组里最近似乎比较轻松，大家都在商量着休息团建之类的事，希望趁这段时间自己能好好补牢一下基础吧！</p><p><img src="/img/2021-07-18-Internship/%E5%8E%A6%E5%A4%A7&%E8%85%BE%E8%AE%AF.jpeg" alt="厦大&amp;&amp;腾讯，七月的收获"></p><p>上午的工作间隙，还收到了前些时参加的厦门大学夏令营优营的通知，也是一个小惊喜吧！（关于夏令营的具体日记可以看这篇~ <a href="https://dragonbra.github.io/2021/10/26/2021/2021-10-26-XMU-Summer-Camp/">2021厦门大学CS保研经历 | 夏令营游记 | MAC实验室</a> ）顺便用云打印打了一下优营承诺书，不得不说这个纸的质量也是真好……拿着我的木头铅笔在上面甚至有点画不出印子来，太厚了。</p><h1 id="感想"><a href="#感想" class="headerlink" title="感想"></a>感想</h1><p>在写下这篇博客的时候，我在腾讯实习的”第一周“（半个）也是要结束啦！</p><p>趁着周末的时间去把房子租了，感慨一下：短租房真的好难租啊！！七月的深圳真的好难找房啊！！不过最终也还算好，不到三千的价格在自如上租到了公司半小时通勤的位置的一个单间，至少比想象中的大出血要好得多了，明天早上就要从腾讯提供的中转住宿里退房搬到新住处啦，希望一切顺利~</p><p>另外，腾讯的周末好像是真的不加班啊，995企业名不虚传？本来想着这两天去逛逛各个办公楼的爱马哥（image咖啡），淘淘咖啡杯之类的周边，结果被告知周末都不开门。两天也都去了趟公司，基本也没有什么人在，感觉挺好的！（当然也可能只是刚好来对时间了哈哈哈）</p><p>预祝自己在接下来两个月时间里收获满满吧~当然，如果回学校了还能出来，那就是三个月吧~</p>]]></content>
    
    
    <categories>
      
      <category>学习与工作</category>
      
    </categories>
    
    
    <tags>
      
      <tag>腾讯实习</tag>
      
      <tag>日记</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
